{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"First we import the necessary libraries\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=2,center=False).mean()\n",
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=3,center=False).mean()\n",
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=4,center=False).mean()\n",
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=5,center=False).mean()\n",
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=6,center=False).mean()\n",
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=7,center=False).mean()\n",
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=8,center=False).mean()\n",
      "C:\\Users\\Leslie\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: FutureWarning: pd.rolling_mean is deprecated for Series and will be removed in a future version, replace with \n",
      "\tSeries.rolling(window=9,center=False).mean()\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Grab our csv files and import as DataFrames\"\"\"\n",
    "SP500 = pd.read_csv('../Data/SP500_new.csv', parse_dates=True)\n",
    "Nasdaq = pd.read_csv('../Data/Nasdaq_new.csv', parse_dates=True)\n",
    "DJI = pd.read_csv('../Data/DJI_new.csv', parse_dates=True)\n",
    "DAX = pd.read_csv('../Data/DAX_new.csv', parse_dates=True)\n",
    "Paris = pd.read_csv('../Data/Paris_new.csv', parse_dates=True)\n",
    "Tokyo = pd.read_csv('../Data/Tokyo_new.csv', parse_dates=True)\n",
    "HongKong = pd.read_csv('../Data/HongKong_new.csv', parse_dates=True)\n",
    "Aus = pd.read_csv('../Data/Aus_new.csv', parse_dates=True)\n",
    "\n",
    "\"\"\"Our target variable is tomorrow's Adj Close\"\"\"\n",
    "target_raw = (SP500['Adj Close'].shift(-1)/SP500['Adj Close'])-1\n",
    "\n",
    "datasets = [SP500, Nasdaq, DJI, DAX, Paris, Tokyo, HongKong, Aus]\n",
    "names = ['SP500', 'Nasdaq', 'DJI', 'DAX', 'Paris', 'Tokyo', 'HongKong', 'Aus']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The generate_features function performs feature engineering using Adj Close,\n",
    "the features generated are Daily Returns, Momentum (Daily Returns over 2 days),\n",
    "Daily Return SMA and lagging Daily Returns\n",
    "\"\"\"\n",
    "\n",
    "def generate_features(datasets, DR, DR_SMA, Lagging):\n",
    "    Max = max(DR, DR_SMA, Lagging+1)\n",
    "    for i in range(len(datasets)):\n",
    "        dataset = datasets[i]\n",
    "        name = names[i]\n",
    "        for j in range(1, DR+1):\n",
    "            dataset[name+'_'+str(j)+'DailyReturn'] = (dataset['Adj Close']/dataset['Adj Close'].shift(j))-1\n",
    "        for k in range(2, DR_SMA+1):\n",
    "            dataset[name+'_'+str(k)+'DR_SMA'] = pd.rolling_mean(dataset[name+'_'+str(1)+'DailyReturn'], window=k)\n",
    "        for l in range(1, Lagging+1):\n",
    "            dataset[name+'_'+str(l)+'LaggingDays'] = dataset[name+'_'+str(1)+'DailyReturn'].shift(l)\n",
    "        dataset.drop(dataset.index[:Max], inplace=True)\n",
    "    return Max\n",
    "\n",
    "\"\"\"After feature engineering, merge all datasets and drop the 'useless' features\"\"\"\n",
    "def merge_datasets(datasets):\n",
    "    drop_features = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Date']\n",
    "    for i in range(len(datasets)):\n",
    "        datasets[i] = datasets[i].drop(drop_features, axis=1)\n",
    "    megaset = pd.concat(datasets, axis=1)\n",
    "    return megaset\n",
    "\n",
    "generate_features(datasets, 9, 9, 9)\n",
    "megaset = merge_datasets(datasets)\n",
    "\n",
    "\"\"\"Label encode our target variable, 1 for increase, 0 for decrease or no change\"\"\"\n",
    "target = target_raw[Max:]\n",
    "target[target > 0] = 1\n",
    "target[target <= 0] = 0\n",
    "\n",
    "\"\"\"Split our megaset into training and cross-validation (test) subsets\"\"\"\n",
    "X_train = megaset[:-500]\n",
    "X_test = megaset[-500:-1]\n",
    "y_train = target[:-500]\n",
    "y_test = target[-500:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Linear: [Accuracy: 0.5351, f1-score: 0.6971]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Support Vector Classifier with Linear Kernel\"\"\"\n",
    "clf1 = svm.SVC(kernel = 'linear')\n",
    "clf1.fit(X_train, y_train)\n",
    "clf1_predictions = clf1.predict(X_test)\n",
    "clf1_accuracy = accuracy_score(y_test, clf1_predictions)\n",
    "clf1_f1 = f1_score(y_test, clf1_predictions)\n",
    "print(\"SVM Linear: [Accuracy: {:.4f}, f1-score: {:.4f}]\".format(clf1_accuracy, clf1_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RBF: [Accuracy: 0.5351, f1-score: 0.6971]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Support Vector Classifier with RBF Kernel\"\"\"\n",
    "clf2 = svm.SVC(kernel = 'rbf')\n",
    "clf2.fit(X_train, y_train)\n",
    "clf2_predictions = clf2.predict(X_test)\n",
    "clf2_accuracy = accuracy_score(y_test, clf2_predictions)\n",
    "clf2_f1 = f1_score(y_test, clf2_predictions)\n",
    "print(\"SVM RBF: [Accuracy: {:.4f}, f1-score: {:.4f}]\".format(clf2_accuracy, clf2_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kNN: [Accuracy: 0.5210, f1-score: 0.5755]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"k-Nearest Neighbours\"\"\"\n",
    "clf3 = KNeighborsClassifier(n_neighbors = 3)\n",
    "clf3.fit(X_train, y_train)\n",
    "clf3_predictions = clf3.predict(X_test)\n",
    "clf3_accuracy = accuracy_score(y_test, clf3_predictions)\n",
    "clf3_f1 = f1_score(y_test, clf3_predictions)\n",
    "print(\"kNN: [Accuracy: {:.4f}, f1-score: {:.4f}]\".format(clf3_accuracy, clf3_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree: [Accuracy: 0.4930, f1-score: 0.5289]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Decision Tree Classifier\"\"\"\n",
    "clf4 = tree.DecisionTreeClassifier()\n",
    "clf4.fit(X_train, y_train)\n",
    "clf4_predictions = clf4.predict(X_test)\n",
    "clf4_accuracy = accuracy_score(y_test, clf4_predictions)\n",
    "clf4_f1 = f1_score(y_test, clf4_predictions)\n",
    "print(\"Decision Tree: [Accuracy: {:.4f}, f1-score: {:.4f}]\".format(clf4_accuracy, clf4_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier: [Accuracy: 0.4930, f1-score: 0.5289]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Random Forest Classifier\"\"\"\n",
    "clf5 = RandomForestClassifier(n_estimators=10)\n",
    "clf5.fit(X_train, y_train)\n",
    "clf5_predictions = clf4.predict(X_test)\n",
    "clf5_accuracy = accuracy_score(y_test, clf5_predictions)\n",
    "clf5_f1 = f1_score(y_test, clf5_predictions)\n",
    "print(\"Random Forest Classifier: [Accuracy: {:.4f}, f1-score: {:.4f}]\".format(clf5_accuracy, clf5_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Classifier: [Accuracy: 0.4990, f1-score: 0.5819]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"AdaBoost Classifier\"\"\"\n",
    "clf6 = AdaBoostClassifier(n_estimators=100)\n",
    "clf6.fit(X_train, y_train)\n",
    "clf6_predictions = clf6.predict(X_test)\n",
    "clf6_accuracy = accuracy_score(y_test, clf6_predictions)\n",
    "clf6_f1 = f1_score(y_test, clf6_predictions)\n",
    "print(\"AdaBoost Classifier: [Accuracy: {:.4f}, f1-score: {:.4f}]\".format(clf6_accuracy, clf6_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier: [Accuracy: 0.5210, f1-score: 0.6470]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Gradient Boosting Classifier\"\"\"\n",
    "clf7 = GradientBoostingClassifier(n_estimators=100)\n",
    "clf7.fit(X_train, y_train)\n",
    "clf7_predictions = clf7.predict(X_test)\n",
    "clf7_accuracy = accuracy_score(y_test, clf7_predictions)\n",
    "clf7_f1 = f1_score(y_test, clf7_predictions)\n",
    "print(\"Gradient Boosting Classifier: [Accuracy: {:.4f}, f1-score: {:.4f}]\".format(clf7_accuracy, clf7_f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
